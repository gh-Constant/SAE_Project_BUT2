# Variables Al√©atoires Continues

---

## üìä D√©finition

Une **variable al√©atoire continue** $X$ est une fonction qui associe √† chaque issue d'une exp√©rience al√©atoire un nombre r√©el :

$$
X : \Omega \rightarrow \mathbb{R}
$$

**Caract√©ristique principale :** Contrairement au cas discret, $X$ peut prendre une **infinit√© de valeurs** dans un intervalle de $\mathbb{R}$ (par exemple $[a,b]$ ou $\mathbb{R}$ tout entier).

### Exemple concret

Soit $X$ la taille d'une personne choisie au hasard. Cette variable peut prendre n'importe quelle valeur dans un intervalle continu (par exemple entre 1,50 m et 2,00 m).

---

## üîÑ Comparaison : Cas discret vs Cas continu

### Variables al√©atoires discr√®tes

Pour une **variable al√©atoire discr√®te** (exemples : nombre de succ√®s, nombre de d√©fauts, r√©sultat d'un lancer de d√©), la loi de probabilit√© est donn√©e par des **masses ponctuelles**.

Chaque valeur enti√®re $k$ poss√®de une probabilit√© associ√©e :

$$
p(k) = P(X = k)
$$

Conna√Ætre les valeurs $P(X = k)$ pour chaque $k$ **d√©crit compl√®tement la loi**.

Pour tout intervalle $[a,b]$ :

$$
P(a \le X \le b) = \sum_{k=a}^{b} p(k)
$$

### Variables al√©atoires continues

√Ä l'inverse, pour une **variable al√©atoire continue** (exemples : taille, dur√©e, poids), on **ne peut plus parler de probabilit√© ponctuelle** :

$$
P(X = x) = 0 \quad \text{pour tout } x \in \mathbb{R}
$$

On utilise alors une **fonction de densit√©** $f(x)$, telle que la probabilit√© qu'une valeur appartienne √† un **intervalle** correspond √† **l'aire sous la courbe** de cette fonction.

> **‚ö†Ô∏è Remarque importante :** $f(x)$ n'est **pas** une probabilit√©, c'est une **densit√© de probabilit√©**.

---

## ‚ùì Probl√©matique

La description d'une loi continue diff√®re fondamentalement de celle d'une loi discr√®te :

### Probabilit√© ponctuelle nulle

Une variable al√©atoire continue $X$ a **une probabilit√© nulle de prendre une valeur exactement d√©termin√©e** :

$$
P(X = x) = 0 \quad \text{pour tout } x \in \mathbb{R}
$$

**Pourquoi ?** Il existe une infinit√© de valeurs possibles dans un intervalle de $\mathbb{R}$, donc le ¬´ poids ¬ª d'une valeur pr√©cise est infinit√©simal (nul).

### Exemple illustratif

Si $X$ d√©signe la taille d'un individu :

$$
P\bigl(X = 1{,}824902139821398\ldots\bigr) = 0
$$

### Cons√©quence

Il n'est donc **pas possible de d√©finir la loi de $X$ √† partir des probabilit√©s ponctuelles**, comme dans le cas discret.

En revanche, on peut d√©crire la loi d'une variable continue gr√¢ce √† la **fonction de r√©partition** et √† la **fonction de densit√©**.

---

## üìà Fonction de r√©partition

### D√©finition

La **fonction de r√©partition** $F$ est d√©finie par :

$$
F(x) = P(X \le x) \quad \text{pour tout } x \in \mathbb{R}
$$

Elle permet de calculer les probabilit√©s que $X$ prenne ses valeurs dans une partie de $\mathbb{R}$.

### Interpr√©tation

**$F(x) = P(X \le x)$ est la passerelle** entre la densit√© de probabilit√© et les probabilit√©s d'intervalles.

---

## üìê Loi de probabilit√© d'une variable continue

### Relation entre densit√© et r√©partition

La loi de probabilit√© de $X$ est d√©finie par une **fonction de r√©partition** $F$, elle-m√™me d√©crite par une **fonction de densit√© de probabilit√©** $f$, telle que :

$$
F(t) = \int_{-\infty}^{t} f(x) \, \mathrm{d}x
$$

o√π :

$$
f : \mathbb{R} \rightarrow [0, +\infty[
$$

### Probabilit√© d'un intervalle

De ce fait, pour tout intervalle $[a,b]$ :

$$
P(a \le X \le b) = \int_a^b f(x) \, \mathrm{d}x
$$

La probabilit√© que $X$ se trouve dans un intervalle $[a,b]$ appara√Æt alors comme **l'aire sous la courbe** de la densit√© $f$ entre $a$ et $b$, au-dessus de l'axe des abscisses.

### Illustration graphique

![Fonction de densit√© de probabilit√©](density.png)

_Figure : Illustration de la probabilit√© comme aire sous la courbe de densit√© entre $a$ et $b$._

---

## ‚úÖ Propri√©t√©s

### Propri√©t√©s de la fonction de r√©partition $F$

1. $F$ est une fonction **continue** (par morceaux) et **croissante**
2. Limites aux bornes :
   $$
   \lim_{x \to -\infty} F(x) = 0 \quad \text{et} \quad \lim_{x \to +\infty} F(x) = 1
   $$

### Propri√©t√©s de la fonction de densit√© $f$

1. **Probabilit√© d'un intervalle :** Pour tout intervalle $[a,b]$, la probabilit√© que $X$ prenne une valeur dans $[a,b]$ est donn√©e par :

   $$
   P(a \le X \le b) = \int_a^b f(x) \, \mathrm{d}x
   $$

2. **Normalisation :** La densit√© $f$ v√©rifie :
   $$
   \int_{-\infty}^{+\infty} f(x) \, \mathrm{d}x = 1
   $$

---

## üìä Esp√©rance et variance

### D√©finition

Soit $X$ une variable al√©atoire continue de $\Omega$ dans $\mathbb{R}$ de densit√© $f$. On calcule l'esp√©rance et la variance √† l'aide des formules suivantes :

### Esp√©rance math√©matique

L'**esp√©rance** (ou moyenne) de $X$ est d√©finie par :

$$
E(X) = \int_{-\infty}^{+\infty} x \cdot f(x) \, \mathrm{d}x
$$

### Variance

La **variance** de $X$ mesure la dispersion autour de l'esp√©rance :

$$
V(X) = E\bigl[(X - E(X))^2\bigr] = \int_{-\infty}^{+\infty} (x - E(X))^2 \cdot f(x) \, \mathrm{d}x
$$

**Formule alternative (souvent plus pratique pour les calculs) :**

$$
V(X) = E(X^2) - [E(X)]^2
$$

---

## üé≤ Lois usuelles

### 3.1 Loi uniforme

Cette loi mod√©lise un ph√©nom√®ne **uniforme** sur un intervalle donn√©.

#### D√©finition

La variable al√©atoire $X$ suit une **loi uniforme** sur l'intervalle born√© $[a,b]$ si elle a une densit√© **constante** sur cet intervalle et **nulle** en dehors de l'intervalle.

**Notation :** $X \sim \mathcal{U}(a,b)$

Cette loi est l'√©quivalent continu de la loi uniforme discr√®te.

#### Fonction de densit√©

$$
f(x) = \begin{cases}
\dfrac{1}{b-a} & \text{si } x \in [a,b] \\[0.5em]
0 & \text{sinon}
\end{cases}
$$

#### Esp√©rance et variance

- **Esp√©rance :**

  $$
  E(X) = \frac{a+b}{2}
  $$

- **Variance :**
  $$
  V(X) = \frac{(b-a)^2}{12}
  $$

---

### 3.2 Loi exponentielle

#### D√©finition

Soit $\lambda$ un r√©el strictement positif. La variable al√©atoire $X$ suit une **loi exponentielle** de param√®tre $\lambda$, not√©e $\mathcal{E}(\lambda)$, si elle admet pour densit√© :

$$
f(x) = \begin{cases}
\lambda \cdot e^{-\lambda x} & \text{si } x \in [0, +\infty[ \\[0.5em]
0 & \text{sinon}
\end{cases}
$$

#### Esp√©rance et variance

- **Esp√©rance :**

  $$
  E(X) = \frac{1}{\lambda}
  $$

- **Variance :**
  $$
  V(X) = \frac{1}{\lambda^2}
  $$

#### Illustration graphique

![Fonction de densit√© exponentielle](schemaexponentielle.png)

_Figure : Illustration de la fonction de densit√© de la loi exponentielle._

#### Applications

Les lois exponentielles sont souvent utilis√©es pour mod√©liser des **temps d'attente** ou des **dur√©es de vie**. Exemples :

- Temps d'attente jusqu'au prochain tremblement de terre
- Dur√©e de vie avant la prochaine panne d'un appareil
- Temps avant la prochaine d√©sint√©gration d'un noyau radioactif
- Intervalle de temps entre deux √©v√©nements dans un processus de Poisson

---

### 3.3 Loi normale ou Gaussienne

La loi normale est le mod√®le naturel pour les **erreurs de mesure** et les ph√©nom√®nes avec beaucoup de petites causes ind√©pendantes.

#### D√©finition

On dit que $X$ suit une **loi normale** (ou **loi gaussienne**) de param√®tres $\mu$ (moyenne) et $\sigma^2$ (variance), not√©e $X \sim \mathcal{N}(\mu, \sigma^2)$, si sa densit√© est :

$$
f(x) = \frac{1}{\sigma \sqrt{2\pi}} \cdot e^{-\frac{(x-\mu)^2}{2\sigma^2}}
$$

> **üìù Remarque :** Certains auteurs utilisent la notation $N(\mu, \sigma^2)$ au lieu de $\mathcal{N}(\mu, \sigma^2)$.

#### Illustration graphique

![Fonction de densit√© normale](loinomrale.png)

_Figure : Illustration de la fonction de densit√© de la loi normale._

#### Esp√©rance et variance

- **Esp√©rance :**

  $$
  E(X) = \mu
  $$

- **Variance :**
  $$
  V(X) = \sigma^2
  $$

#### Concentration autour de la moyenne

**R√®gle 68-95-99,7** (rep√®res rapides) :

La loi normale pr√©sente une propri√©t√© remarquable de **concentration des valeurs autour de la moyenne** $\mu$. Cette concentration peut √™tre quantifi√©e pr√©cis√©ment √† l'aide de l'√©cart-type $\sigma$ :

- **Intervalle √† 1 √©cart-type :** Dans l'intervalle $[\mu - \sigma, \mu + \sigma]$, de **longueur $2\sigma$** et **centr√© autour de la moyenne** $\mu$, on peut observer environ **68%** des individus lorsque la variable al√©atoire suit une loi normale.

- **Intervalle √† 2 √©carts-types :** Dans l'intervalle $[\mu - 2\sigma, \mu + 2\sigma]$, de **longueur $4\sigma$** et **centr√© autour de la moyenne** $\mu$, on peut observer environ **95%** des individus lorsque la variable al√©atoire suit une loi normale.

- **Intervalle √† 3 √©carts-types :** Dans l'intervalle $[\mu - 3\sigma, \mu + 3\sigma]$, de **longueur $6\sigma$** et **centr√© autour de la moyenne** $\mu$, on peut observer environ **99,7%** des individus lorsque la variable al√©atoire suit une loi normale.

> **üí° Interpr√©tation pratique :** Ces intervalles permettent de comprendre la dispersion des donn√©es. Par exemple, si $\mu = 170$ cm et $\sigma = 10$ cm pour la taille d'une population :
>
> - 68% des individus mesurent entre 160 cm et 180 cm (intervalle $[170-10, 170+10]$)
> - 95% des individus mesurent entre 150 cm et 190 cm (intervalle $[170-20, 170+20]$)
> - 99,7% des individus mesurent entre 140 cm et 200 cm (intervalle $[170-30, 170+30]$)

> **‚ö†Ô∏è Condition d'application :** Cette r√®gle ne s'applique que lorsque la distribution des donn√©es suit effectivement une **loi normale**. Pour d'autres distributions (asym√©triques, multimodales, etc.), ces pourcentages ne sont pas valables.

---
